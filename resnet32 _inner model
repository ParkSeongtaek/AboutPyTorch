#1. Module Import
import numpy as np
import matplotlib as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets
import torchvision.models as models
from torch.utils.data import DataLoader 

#2. DEVICE
if torch.cuda.is_available():
    DEVICE = torch.device('cuda')
else:
    DEVICE = torch.device('cpu')


#3. HYPHER PARAMETER
BATCH_SIZE = 32
EPOCHS = 10

#4. DataDownload
train_dataset = datasets.CIFAR10(root = 'CIFAR_10/',
                                 train = True,
                                 download = True,
                                 transform = transforms.Compose( [
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5,0.5,0.5), 
                                                          (0.5,0.5,0.5))]))
test_dataset = datasets.CIFAR10(root = 'CIFAR_10/',
                                 train = False,
                                 download = True,
                                 transform = transforms.Compose( [
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5,0.5,0.5),
                                                          (0.5,0.5,0.5))]))

train_loader = DataLoader(dataset = train_dataset,
                          batch_size= BATCH_SIZE,
                          shuffle= True,
                          drop_last= True)

test_loader = DataLoader(dataset = test_dataset,
                          batch_size= BATCH_SIZE,
                          shuffle= False
                          )



#5. Data check 1 
for (X_train,Y_train) in train_loader:
    print('X_train: ' , X_train.size(),'type: ', X_train.type())
    print('Y_train: ' , Y_train.size(),'type: ', Y_train.type())
    break

#7. OPtimizer,Objective Function
model = models.resnet34(pretrained = False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs,10)
model = model.to(DEVICE)

optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)
criterion = nn.CrossEntropyLoss()

print(model)

#8. MLP Model
def train(model,train_loader,optimizer,log_interval):
    model.train()
    for batch_idx,(image , label )in enumerate(train_loader):
        image = image.to(DEVICE)
        label = label.to(DEVICE)
        optimizer.zero_grad()
        output = model(image)
        loss = criterion(output,label)

        loss.backward()
        optimizer.step()

        if batch_idx % log_interval == 0:
            print("Train Epoch: {} [ {}/{} ( {:.0f}% ) ]\t Train Loss: {:.6f} ".format (
               Epoch, batch_idx * len(image),
               len(train_loader.dataset), 100. * batch_idx / len (train_loader), 
               loss.item()))

#9. evaluate
def evaluate(model, test_loader):
    model.eval()
    test_loss = 0
    correct = 0

    with torch.no_grad():
        for image, label in test_loader:
            image = image.to(DEVICE)
            label = label.to(DEVICE)
            output = model(image)
            test_loss += criterion(output,label).item()
            prediction = output.max(1,keepdim = True)[1]
            correct += prediction.eq(label.view_as(prediction)).sum().item()

    test_loss /= len(test_loader.dataset)
    test_accuracy = 100. * correct / len(test_loader.dataset)
    return test_loss,test_accuracy


#10.
for Epoch in range(1, EPOCHS + 1):
    train(model, train_loader, optimizer,log_interval = 200)
    test_loss,test_accuracy = evaluate(model, test_loader)
    print("\n[EPOCH:{}], \t Test Loss : {:.4f}, \t Test Accuracy: {:.2f} % \n"
          .format(Epoch,test_loss,test_accuracy))
